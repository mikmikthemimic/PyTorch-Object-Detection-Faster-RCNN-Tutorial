{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import logging\n",
    "import json\n",
    "import pathlib\n",
    "from itertools import chain\n",
    "import numpy\n",
    "import os\n",
    "import pandas\n",
    "\n",
    "from metrics.enumerators import MethodAveragePrecision\n",
    "from metrics.pascal_voc_evaluator import (\n",
    "    get_pascalvoc_metrics,\n",
    ")\n",
    "from utils import (\n",
    "    from_file_to_boundingbox,\n",
    "    get_filenames_of_path,\n",
    ")\n",
    "\n",
    "logger: logging.Logger = logging.getLogger(__name__)\n",
    "\n",
    "# root directory\n",
    "FOLDER_PATH = pathlib.Path(os.getcwd()).parent.absolute()\n",
    "MODULE_PATH = FOLDER_PATH.parent.absolute() / \"PyTorch-Object-Detection-Faster-RCNN-Tutorial\"\n",
    "DATA_PATH = MODULE_PATH / \"pytorch_faster_rcnn_tutorial\" / \"data\" / \"heads\"\n",
    "\n",
    "\n",
    "# input and target files\n",
    "predictions = get_filenames_of_path(DATA_PATH / \"predictions\")\n",
    "predictions.sort()\n",
    "# test-target files\n",
    "gt_predictions = get_filenames_of_path(DATA_PATH / \"test_targets\")\n",
    "gt_predictions.sort()\n",
    "\n",
    "\n",
    "# get the gt_boxes from disk  || test-targets\n",
    "gt_boxes = [\n",
    "    from_file_to_boundingbox(file_name, groundtruth=True)\n",
    "    for file_name in gt_predictions\n",
    "]\n",
    "# reduce list\n",
    "gt_boxes = list(chain(*gt_boxes))\n",
    "\n",
    "pred_boxes = [\n",
    "    from_file_to_boundingbox(file_name, groundtruth=False)\n",
    "    for file_name in predictions\n",
    "]\n",
    "pred_boxes = list(chain(*pred_boxes))\n",
    "\n",
    "output = get_pascalvoc_metrics(\n",
    "    gt_boxes=gt_boxes,\n",
    "    det_boxes=pred_boxes,\n",
    "    iou_threshold=0.50,\n",
    "    method=MethodAveragePrecision.EVERY_POINT_INTERPOLATION,\n",
    "    generate_table=True,\n",
    ")\n",
    "\n",
    "per_class, m_ap = output[\"per_class\"], output[\"m_ap\"]\n",
    "#print(per_class)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision <class 'numpy.ndarray'>\n",
      "recall <class 'numpy.ndarray'>\n",
      "AP <class 'numpy.float64'>\n",
      "interpolated precision <class 'list'>\n",
      "interpolated recall <class 'list'>\n",
      "total positives <class 'int'>\n",
      "total tp <class 'numpy.float64'>\n",
      "total fp <class 'numpy.float64'>\n",
      "method <enum 'MethodAveragePrecision'>\n",
      "iou <class 'float'>\n",
      "table <class 'pandas.core.frame.DataFrame'>\n",
      "precision <class 'numpy.ndarray'>\n",
      "recall <class 'numpy.ndarray'>\n",
      "AP <class 'numpy.float64'>\n",
      "interpolated precision <class 'list'>\n",
      "interpolated recall <class 'list'>\n",
      "total positives <class 'int'>\n",
      "total tp <class 'numpy.float64'>\n",
      "total fp <class 'numpy.float64'>\n",
      "method <enum 'MethodAveragePrecision'>\n",
      "iou <class 'float'>\n",
      "table <class 'pandas.core.frame.DataFrame'>\n",
      "precision <class 'numpy.ndarray'>\n",
      "recall <class 'numpy.ndarray'>\n",
      "AP <class 'numpy.float64'>\n",
      "interpolated precision <class 'list'>\n",
      "interpolated recall <class 'list'>\n",
      "total positives <class 'int'>\n",
      "total tp <class 'numpy.float64'>\n",
      "total fp <class 'numpy.float64'>\n",
      "method <enum 'MethodAveragePrecision'>\n",
      "iou <class 'float'>\n",
      "table <class 'pandas.core.frame.DataFrame'>\n",
      "precision <class 'numpy.ndarray'>\n",
      "recall <class 'numpy.ndarray'>\n",
      "AP <class 'numpy.float64'>\n",
      "interpolated precision <class 'list'>\n",
      "interpolated recall <class 'list'>\n",
      "total positives <class 'int'>\n",
      "total tp <class 'numpy.float64'>\n",
      "total fp <class 'numpy.float64'>\n",
      "method <enum 'MethodAveragePrecision'>\n",
      "iou <class 'float'>\n",
      "table <class 'pandas.core.frame.DataFrame'>\n",
      "precision <class 'numpy.ndarray'>\n",
      "recall <class 'numpy.ndarray'>\n",
      "AP <class 'numpy.float64'>\n",
      "interpolated precision <class 'list'>\n",
      "interpolated recall <class 'list'>\n",
      "total positives <class 'int'>\n",
      "total tp <class 'numpy.float64'>\n",
      "total fp <class 'numpy.float64'>\n",
      "method <enum 'MethodAveragePrecision'>\n",
      "iou <class 'float'>\n",
      "table <class 'pandas.core.frame.DataFrame'>\n",
      "precision <class 'numpy.ndarray'>\n",
      "recall <class 'numpy.ndarray'>\n",
      "AP <class 'numpy.float64'>\n",
      "interpolated precision <class 'list'>\n",
      "interpolated recall <class 'list'>\n",
      "total positives <class 'int'>\n",
      "total tp <class 'numpy.float64'>\n",
      "total fp <class 'numpy.float64'>\n",
      "method <enum 'MethodAveragePrecision'>\n",
      "iou <class 'float'>\n",
      "table <class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "labels = [\"Pedestrian\", \"Pedestrian-Violator\", \"Vehicle\", \"Vehicle-Violator\", \"Bicycle\", \"Bicycle-Violator\"]\n",
    "\n",
    "for label in labels:\n",
    "    head = per_class[label]\n",
    "    for key, value in head.items():\n",
    "        print(key, type(value))\n",
    "        if isinstance(value, numpy.ndarray):\n",
    "            head[key] = value.tolist()\n",
    "        if isinstance(value, MethodAveragePrecision):\n",
    "            head[key] = str(value)\n",
    "        if isinstance(value, pandas.core.frame.DataFrame):\n",
    "            head[key] = value.to_dict()\n",
    "        if isinstance(value, numpy.int32):\n",
    "            head[key] = int(value)\n",
    "\n",
    "    with open(f'my ground truths/GMT3-558/{label}.json', 'w') as f:\n",
    "        json.dump(head, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
